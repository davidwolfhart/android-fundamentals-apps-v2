{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwolfhart/android-fundamentals-apps-v2/blob/master/quickstarts/Video_understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5yiH5h8x3h"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGdicu8PVD9"
      },
      "source": [
        "# Video understanding with Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR4Ti6Q0QKIl"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w14yjWnPVD-"
      },
      "source": [
        "Gemini has from the begining been a multimodal model, capable of analyzing all sorts of medias using its [long context window](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/).\n",
        "\n",
        "[Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) and later bring video analysis to a whole new level as illustrated in [this video](https://www.youtube.com/watch?v=Mot-JEU26GQ):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CumMaR-sts53",
        "outputId": "6fb757f6-e500-4aee-dfc5-580cde6a4095"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Mot-JEU26GQ?si=pcb7-_MZTSi_1Zkw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Building with Gemini 2.0: Video understanding\n",
        "%%html\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Mot-JEU26GQ?si=pcb7-_MZTSi_1Zkw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jexx9acnuDsA"
      },
      "source": [
        "This notebook will show you how to easily use Gemini to perform the same kind of video analysis. Each of them has different prompts that you can select using the dropdown, also feel free to experiment with your own.\n",
        "\n",
        "You can also check the [live demo](https://aistudio.google.com/starter-apps/video) and try it on your own videos on [AI Studio](https://aistudio.google.com/starter-apps/video)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0HWzIEAQYqz"
      },
      "source": [
        "## Setup\n",
        "\n",
        "This section install the SDK, set it up using your [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n",
        "\n",
        "Expand the section if you are curious, but you can also just run it (it should take a couple of minutes since there are large files) and go straight to the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzBKAaL4QYq0"
      },
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both. This means that you can prototype an application using the Developer API and then migrate the application to Vertex AI without rewriting your code.\n",
        "\n",
        "More details about this new SDK on the [documentation](https://ai.google.dev/gemini-api/docs/sdks) or in the [Getting started](../quickstarts/Get_started.ipynb) notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q 'google-genai'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDUGen_kQYq2"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY_2025')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Lez1vBQYq3"
      },
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK you now only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITgsQyaXQYq4"
      },
      "source": [
        "### Select the Gemini model\n",
        "\n",
        "Video understanding works best Gemini 2.5 pro model. You can also select former models to compare their behavior but it is recommended to use at least the 2.0 ones.\n",
        "\n",
        "For more information about all Gemini models, check the [documentation](https://ai.google.dev/gemini-api/docs/models/gemini) for extended information on each of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "source": [
        "model_name = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-05-06\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv8ULT0lvJ47"
      },
      "source": [
        "### Get sample videos\n",
        "\n",
        "You will start with uploaded videos, as it's a more common use-case, but you will also see later that you can also use Youtube videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fMcwUw48vL1N"
      },
      "outputs": [],
      "source": [
        "# Load sample images\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4 -O Pottery.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4 -O Trailcam.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4 -O Post_its.mp4 -q\n",
        "!wget https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4 -O User_study.mp4 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4YMNQulz_yY"
      },
      "source": [
        "### Upload the videos\n",
        "\n",
        "Upload all the videos using the File API. You can find modre details about how to use it in the [Get Started](../quickstarts/Get_started.ipynb#scrollTo=KdUjkIQP-G_i) notebook.\n",
        "\n",
        "This can take a couple of minutes as the videos will need to be processed and tokenized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LUUMJ4kE0OZS",
        "outputId": "9b53d6eb-eeaf-4b2f-eaa3-314c7fd02802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/ndvzj4blgxo3\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/21b05ndbv8mg\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/rt570xd5e1v2\n",
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/mt29kj60n8m1\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "pottery_video = upload_video('Pottery.mp4')\n",
        "trailcam_video = upload_video('Trailcam.mp4')\n",
        "post_its_video = upload_video('Post_its.mp4')\n",
        "user_study_video = upload_video('User_study.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAa7sCD7tuMW"
      },
      "source": [
        "# Search within videos\n",
        "\n",
        "First, try using the model to search within your videos and describe all the animal sightings in the trailcam video.\n",
        "\n",
        "<video controls width=\"500\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PZw41-lsKKMf",
        "outputId": "b4941ca2-1378-4598-f883-ad52144afd87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"00:00\",\n    \"caption\": \"A camera view of the ground and leaves.\"\n  },\n  {\n    \"timecode\": \"00:01\",\n    \"caption\": \"Two gray foxes are on the forest floor near rocks, sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"00:17\",\n    \"caption\": \"A mountain lion walks through the forest at night, sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"00:28\",\n    \"caption\": \"The mountain lion lifts its head and looks around.\"\n  },\n  {\n    \"timecode\": \"00:33\",\n    \"caption\": \"The mountain lion walks away.\"\n  },\n  {\n    \"timecode\": \"00:35\",\n    \"caption\": \"Two gray foxes are on the ground at night. One suddenly jumps up.\"\n  },\n  {\n    \"timecode\": \"00:45\",\n    \"caption\": \"The two foxes interact briefly and then one runs off.\"\n  },\n  {\n    \"timecode\": \"00:50\",\n    \"caption\": \"A loud noise is heard, and the camera lens flashes.\"\n  },\n  {\n    \"timecode\": \"00:51\",\n    \"caption\": \"Several gray foxes are seen reacting to the noise, some running up rocky terrain.\"\n  },\n  {\n    \"timecode\": \"00:57\",\n    \"caption\": \"A fox looks towards the camera with glowing eyes.\"\n  },\n  {\n    \"timecode\": \"01:00\",\n    \"caption\": \"Foxes continue moving around on the rocks.\"\n  },\n  {\n    \"timecode\": \"01:05\",\n    \"caption\": \"A mountain lion walks into view at night and looks around.\"\n  },\n  {\n    \"timecode\": \"01:10\",\n    \"caption\": \"The mountain lion walks away.\"\n  },\n  {\n    \"timecode\": \"01:18\",\n    \"caption\": \"Two mountain lions are walking on rocks at night, with their eyes glowing.\"\n  },\n  {\n    \"timecode\": \"01:24\",\n    \"caption\": \"One mountain lion walks off a rock and past the camera.\"\n  },\n  {\n    \"timecode\": \"01:29\",\n    \"caption\": \"A bobcat stands and looks around at night, then sniffs the ground.\"\n  },\n  {\n    \"timecode\": \"01:41\",\n    \"caption\": \"The bobcat sits down briefly then stands back up, looking around.\"\n  },\n  {\n    \"timecode\": \"01:45\",\n    \"caption\": \"The bobcat sniffs the ground again.\"\n  },\n  {\n    \"timecode\": \"01:51\",\n    \"caption\": \"A black bear walks into view during the day, sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"01:54\",\n    \"caption\": \"The bear walks away.\"\n  },\n  {\n    \"timecode\": \"01:57\",\n    \"caption\": \"A mountain lion walks through the forest at dusk/night, with glowing eyes.\"\n  },\n  {\n    \"timecode\": \"02:04\",\n    \"caption\": \"The mountain lion walks out of frame.\"\n  },\n  {\n    \"timecode\": \"02:05\",\n    \"caption\": \"A close view of a bear's fur as it walks past the camera.\"\n  },\n  {\n    \"timecode\": \"02:08\",\n    \"caption\": \"The bear continues walking away.\"\n  },\n  {\n    \"timecode\": \"02:12\",\n    \"caption\": \"Two young bears (cubs) are on the ground, sniffing.\"\n  },\n  {\n    \"timecode\": \"02:18\",\n    \"caption\": \"The two cubs continue sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"02:23\",\n    \"caption\": \"A gray fox is on a hillside at night with city lights in the distance, sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"02:31\",\n    \"caption\": \"The fox sits and looks out at the city lights.\"\n  },\n  {\n    \"timecode\": \"02:35\",\n    \"caption\": \"A black bear walks past the camera on the hillside at night.\"\n  },\n  {\n    \"timecode\": \"02:42\",\n    \"caption\": \"A mountain lion walks into view on the hillside at night, sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"02:49\",\n    \"caption\": \"The mountain lion walks out of frame.\"\n  },\n  {\n    \"timecode\": \"02:52\",\n    \"caption\": \"A mountain lion is sniffing the ground near a tree at night.\"\n  },\n  {\n    \"timecode\": \"03:00\",\n    \"caption\": \"The mountain lion stands up and looks around.\"\n  },\n  {\n    \"timecode\": \"03:04\",\n    \"caption\": \"The mountain lion walks away.\"\n  },\n  {\n    \"timecode\": \"03:05\",\n    \"caption\": \"A black bear stands on the forest floor during the day, looking around and making sounds.\"\n  },\n  {\n    \"timecode\": \"03:13\",\n    \"caption\": \"The bear looks to the side.\"\n  },\n  {\n    \"timecode\": \"03:22\",\n    \"caption\": \"A black bear walks into view and sniffs the ground. Another bear joins it.\"\n  },\n  {\n    \"timecode\": \"03:30\",\n    \"caption\": \"Both bears are sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"03:39\",\n    \"caption\": \"One bear walks close to the camera.\"\n  },\n  {\n    \"timecode\": \"03:41\",\n    \"caption\": \"The two bears continue sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"03:51\",\n    \"caption\": \"One bear sits down and scratches.\"\n  },\n  {\n    \"timecode\": \"03:58\",\n    \"caption\": \"The sitting bear stands up and walks away, followed by the other bear.\"\n  },\n  {\n    \"timecode\": \"04:02\",\n    \"caption\": \"Two lighter colored bears walk towards the camera, sniffing the ground.\"\n  },\n  {\n    \"timecode\": \"04:12\",\n    \"caption\": \"One lighter colored bear walks past the camera.\"\n  },\n  {\n    \"timecode\": \"04:22\",\n    \"caption\": \"A bobcat sits and looks at the camera at night.\"\n  },\n  {\n    \"timecode\": \"04:25\",\n    \"caption\": \"The bobcat walks off along a log.\"\n  },\n  {\n    \"timecode\": \"04:31\",\n    \"caption\": \"A gray fox walks into view at night, looking at the camera and sniffing.\"\n  },\n  {\n    \"timecode\": \"04:40\",\n    \"caption\": \"The fox walks away.\"\n  },\n  {\n    \"timecode\": \"04:44\",\n    \"caption\": \"Another gray fox walks into view at night, looking at the camera.\"\n  },\n  {\n    \"timecode\": \"04:48\",\n    \"caption\": \"The fox walks away.\"\n  },\n  {\n    \"timecode\": \"04:57\",\n    \"caption\": \"A mountain lion is sniffing the ground near a tree at night.\"\n  },\n  {\n    \"timecode\": \"05:03\",\n    \"caption\": \"The mountain lion looks around.\"\n  },\n  {\n    \"timecode\": \"05:06\",\n    \"caption\": \"The mountain lion walks away.\"\n  }\n]\n```"
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "prompt = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\"  # @param [\"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\", \"Organize all scenes from this video in a table, along with timecode, a short description, a list of objects visible in the scene (with representative emojis) and an estimation of the level of excitement on a scale of 1 to 10\"] {\"allow-input\":true}\n",
        "\n",
        "video = trailcam_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOQzKYGJKAnD"
      },
      "source": [
        "The prompt used is quite a generic one, but you can get even better results if you cutomize it to your needs (like asking specifically for foxes).\n",
        "\n",
        "The [live demo on AI Studio](https://aistudio.google.com/starter-apps/video) shows how you can postprocess this output to jump directly to the the specific part of the video by clicking on the timecodes. If you are interested, you can check the [code of that demo on Github](https://github.com/google-gemini/starter-applets/tree/main/video)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wog32E7CKnT6"
      },
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the video and extract it in an organized way. You can even use Gemini reasoning capabilities to generate new ideas for you.\n",
        "\n",
        "<video controls width=\"400\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "baNCeA3GKrfu",
        "outputId": "27faa069-4979-4f4c-a372-fa163d2d1440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here are the transcribed project name ideas from the sticky notes, organized in a table, along with a few additional ideas based on similar themes.\n\n**Brainstorm: Project Name Ideas from Sticky Notes**\n\n| Project Name        | Potential Category/Theme        |\n| :------------------ | :------------------------------ |\n| Aether              | Mythology, Space                |\n| Andromeda's Reach   | Space, Astronomy                |\n| Astral Forge        | Space, Abstract, Fantasy        |\n| Athena              | Mythology                       |\n| Athena's Eye        | Mythology, Abstract             |\n| Bayes Theorem       | Math, Science                   |\n| Canis Major         | Space, Astronomy (Constellation) |\n| Celestial Drift     | Space, Abstract                 |\n| Centaurus           | Mythology, Astronomy            |\n| Cerberus            | Mythology                       |\n| Chaos Field         | Science, Abstract               |\n| Chaos Theory        | Math, Science                   |\n| Chimera Dream       | Mythology, Abstract, Fantasy    |\n| Comets Tail         | Space, Astronomy                |\n| Convergence         | Math, Science, Abstract         |\n| Delphinus           | Mythology, Astronomy            |\n| Draco               | Mythology, Astronomy            |\n| Echo                | Mythology, Abstract             |\n| Equilibrium         | Math, Science, Abstract         |\n| Euler's Path        | Math, Science                   |\n| Fractal             | Math, Science, Abstract         |\n| Galactic Core       | Space, Astronomy                |\n| Golden Ratio        | Math, Science, Abstract         |\n| Hera                | Mythology                       |\n| Infinity Loop       | Math, Science, Abstract         |\n| Leo Minor           | Space, Astronomy (Constellation) |\n| Lunar Eclipse       | Space, Astronomy                |\n| Lyra                | Mythology, Astronomy            |\n| Lynx                | Mythology, Astronomy            |\n| Medusa              | Mythology                       |\n| Odin                | Mythology                       |\n| Orion's Belt        | Space, Astronomy (Constellation) |\n| Orion's Sword       | Space, Astronomy (Constellation) |\n| Pandora's Box       | Mythology, Abstract             |\n| Persius Shield      | Mythology, Abstract             |\n| Phoenix             | Mythology, Abstract             |\n| Prometheus Rising   | Mythology, Abstract             |\n| Riemann's Hypothesis| Math, Science                   |\n| Sagitta             | Mythology, Astronomy            |\n| Serpens             | Mythology, Astronomy            |\n| Stellar Nexus       | Space, Astronomy                |\n| Stokes Theorem      | Math, Science                   |\n| Supernova Echo      | Space, Astronomy, Abstract      |\n| Symmetry            | Math, Science, Abstract         |\n| Taylor Series       | Math, Science                   |\n| Titan               | Mythology, Space                |\n| Vector              | Math, Science, Abstract         |\n| Zephyr              | Mythology, Abstract             |\n\n**A Few More Project Name Ideas (Based on similar themes):**\n\n1.  **Singularity:** (Space, Math, Abstract - suggests a point of focus or origin)\n2.  **Quantum Leap:** (Science, Abstract - suggests progress, advancement)\n3.  **Aegis:** (Mythology, Abstract - suggests protection, defense)\n4.  **Pulsar:** (Space, Astronomy, Science - suggests rhythm, power)\n5.  **Chronos Engine:** (Mythology, Science, Abstract - suggests time, power, mechanics)\n6.  **Valkyrie:** (Mythology - Norse, suggests strength, selection)\n7.  **Horizon:** (Abstract, Space - suggests a boundary or future)"
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "prompt = \"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\" # @param [\"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\", \"Which of those names who fit an AI product that can resolve complex questions using its thinking abilities?\"] {\"allow-input\":true}\n",
        "\n",
        "video = post_its_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjKIsLDMTNk1"
      },
      "source": [
        "# Structure information\n",
        "\n",
        "Gemini 2.0 is not only able to read text but also to reason and structure about real world objects. Like in this video about a display of ceramics with handwritten prices and notes.\n",
        "\n",
        "<video controls width=\"500\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqzqedMFT5Wp",
        "outputId": "2f2deaae-9e01-40af-ae3c-8648dfb22779"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Okay, here is a table summarizing the items and notes shown in the image:\n\n| Item          | Description / Notes                       | Price |\n| :------------ | :---------------------------------------- | :---- |\n| Tumblers      | Glaze: #5 Artichoke double dip<br>4\"h x 3\"d (-ish) | \\$20  |\n| Small bowls   | 3.5\"h x 6.5\"d                             | \\$35  |\n| Med bowls     | 4\"h x 7\"d                                 | \\$40  |\n| *Glaze Info*  | #5 Artichoke double dip (Test tile shown) | N/A   |\n| *Glaze Info*  | #6 Gemini double dip, SLOW COOL (Test tile shown, marked 6rb) | N/A   |\n\n**Note:** The glaze for the small and medium bowls appears to be the \"#6 Gemini double dip\" based on visual similarity to the test tile, although the notes next to the bowls don't explicitly state the glaze name.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Give me a table of my items and notes\" # @param [\"Give me a table of my items and notes\", \"Help me come up with a selling pitch for my potteries\"] {\"allow-input\":true}\n",
        "\n",
        "video = pottery_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ],\n",
        "    config = types.GenerateContentConfig(\n",
        "        system_instruction=\"Don't forget to escape the dollar signs\",\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsh6i-Z6VHNK"
      },
      "source": [
        "As you can see, Gemini is able to grasp to with item corresponds each note, including the last one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIfsFC0pVUTD"
      },
      "source": [
        "# Analyze screen recordings for key moments\n",
        "\n",
        "You can also use the model to analyze screen recordings. Let's say you're doing user studies on how people use your product, so you end up with lots of screen recordings, like this one, that you have to manually comb through.\n",
        "With just one prompt, the model can describe all the actions in your video.\n",
        "\n",
        "<video controls width=\"400\"><source src=\"https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrMHZ0MxW75y",
        "outputId": "f3cae04c-2bae-468b-b4c0-04c6495b1348"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "Here is a summary of the video:\n\n(00:00-00:10) The video displays a mobile application called \"My Garden App\" showcasing various plants available for purchase.\n(00:10-00:17) The user interacts with the app by clicking the \"Like\" button for the Rose Plant, Fern, and Cactus, turning the buttons red.\n(00:13-00:25) They proceed to add the Fern, Cactus, and Hibiscus plants to the shopping cart, indicated by the \"Add to Cart\" button briefly changing to \"Added!\".\n(00:29-00:34) The user navigates to the \"Cart\" tab, showing the three selected items and the total price, and then briefly views the \"Profile\" tab showing counts for liked plants and cart items.\n(00:37-00:45) After returning to the home screen, the user unlikes the Hibiscus, likes the Snake Plant, and adds the Orchid to their cart.",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\" # @param [\"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\", \"Choose 5 key shots from this video and put them in a table with the timecode, text description of 10 words or less, and a list of objects visible in the scene (with representative emojis).\", \"Generate bullet points for the video. Place each bullet point into an object with the timecode of the bullet point in the video.\"] {\"allow-input\":true}\n",
        "\n",
        "video = user_study_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEYYemjyKcZ7"
      },
      "source": [
        "# Analyze youtube videos\n",
        "\n",
        "On top of using your own videos you can also ask Gemini to get a video from Youtube and analyze it. He's an example using the keynote from Google IO 2023. Guess what the main theme was?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DP0Dd0hJKvYm",
        "outputId": "2632a7c5-e4ff-45c0-de0b-d4e814837ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the video content from 00:00 onwards:\n\nThe video shows a player named David in the game **Digimon Card Battle (PS1)**. He is in the **Battle Arena**, specifically at the **Jungle City** location.\n\nThe player chooses to battle against an opponent named **Ninjamon**. Ninjamon uses a special \"Switching Deck\" which allows it to quickly switch between Digimon levels R and C.\n\nThe video then shows the battle:\n1.  **Preparation Phase:** Both players draw cards and put Digimon into play (Ninjamon starts with Tentomon, David starts with Agumon).\n2.  **Digivolve Phase:** Both players gain Digivolve Points (DP).\n3.  **Battle Phase:**\n    *   David uses a Support Card to boost Agumon's attack power (+300).\n    *   Agumon attacks Tentomon with a \"Deadly Attack\".\n    *   Ninjamon's Tentomon is defeated.\n    *   Ninjamon brings out a new Digimon (Ninjamon C).\n    *   David Digivolves Agumon into Flarelizamon (recovers HP).\n    *   Ninjamon Digivolves into Palmon (R level).\n    *   There is no Battle Phase as Ninjamon has no Digimon in play (Palmon was defeated).\n    *   Ninjamon brings out Ninjamon (C level) again.\n    *   David uses a Support Card (\"Attack Chip\") to boost Flarelizamon's attack power (+300).\n    *   Flarelizamon attacks Ninjamon (C) with a \"Deadly Attack\".\n    *   Ninjamon's Digimon is defeated.\n\nThe battle concludes with **David winning**. The post-battle screen shows David's record (7 Wins, 0 Losses) and Ninjamon's (0 Wins, 1 Loss). David earns experience points (with bonuses for winning using only Circle attacks, not discarding, and not losing) and receives new cards (BomberNanmon, Tsukaomon, Dokunemmon) and a Digi-Part (Counterattack).\n\nThe person in the picture-in-picture window is the player, providing commentary in Indonesian throughout the match, explaining his strategy and reacting to the opponent's moves and the outcome."
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"What is the content of this video?\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri='https://youtu.be/trgzYWgTvuY')\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cizoUEdIYLd0"
      },
      "source": [
        "Once again, you can check the  [live demo on AI Studio](https://aistudio.google.com/starter-apps/video) shows an example on how to postprocess this output. Check the [code of that demo](https://github.com/google-gemini/starter-applets/tree/main/video) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lND4jB6MrsSk"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "Try with you own videos using the [AI Studio's live demo](https://aistudio.google.com/starter-apps/video) or play with the examples from this notebook (in case you haven't seen, there are other prompts you can try in the dropdowns).\n",
        "\n",
        "For more examples of the Gemini capabilities, check the other guide from the [Cookbook](https://github.com/google-gemini/cookbook/). You'll learn how to use the [Live API](../quickstarts/Get_started_LiveAPI.ipynb), juggle with [multiple tools](../quickstarts/Get_started_LiveAPI_tools.ipynb) or use Gemini 2.0 [spatial understanding](../quickstarts/Spatial_understanding.ipynb) abilities.\n",
        "\n",
        "The [examples](https://github.com/google-gemini/cookbook/tree/main/examples/) folder from the cookbook is also full of nice code samples illustrating creative ways to use Gemini multimodal capabilities and long-context."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Video_understanding.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}